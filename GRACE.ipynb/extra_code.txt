import numpy as np
import pandas as pd
from datetime import datetime, timedelta

np.random.seed(2016)

# Generate a datetime range
start_date = datetime(2022, 1, 1)
date_range = [start_date + timedelta(days=i) for i in range(5)]

# Create a 3D array
arr = np.random.randint(0, 1000, (5, 4, 3))

# Reshape the array and create a DataFrame
df = pd.DataFrame(arr.reshape(-1, 3), columns=list('ABC'))

# Use the datetime range as the index
df.index = np.repeat(date_range, arr.shape[1]) + np.tile(np.arange(arr.shape[1]), len(date_range))
df.index.name = 'Date'

print(df)


import numpy as np
import pandas as pd

i = ['2003-06-01', '2004-06-01', '2005-06-01']
arr = [[[2, 3], [4, 5], [6, 7], [0, 1]],
       [[2, 3], [4, 5], [6, 7], [0, 1]],
       [[2, 3], [4, 5], [6, 7], [0, 1]]]

aaa = np.array(arr).reshape(-1, 2)
df = pd.DataFrame(aaa, columns=['A', 'B'])

# Repeat the values in the 'i' list to match the length of the DataFrame
df.index = np.repeat(i, len(arr[0]))

print(df)

# Assuming your DataFrame is named 'df' and 'time' is a datetime column
df1['time'] = pd.to_datetime(df1['time'])
# Add columns for year and month
df1['year'] = df1['time'].dt.year % 100  # Extract last two digits of the year
df1['month'] = df1['time'].dt.month
df1



# Define input features and target variable
X = df1[['lat', 'lon', 'year', 'month']]  # Adjust column names as needed
y = df1['lwe_thickness']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

# Define the model
model = Sequential()

# Input layer
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))

# Hidden layers
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))  # Add dropout for regularization
model.add(Dense(64, activation='relu'))

# Output layer
model.add(Dense(1, activation='linear'))  # Assuming a regression problem

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')  # Use mean squared error for regression

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])

# Predict using the trained model
predictions = model.predict(X_test)
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, predictions)
print("Mean Squared Error ", mse)


from sklearn.ensemble import RandomForestRegressor

# Create and train the model
model1 = RandomForestRegressor(n_estimators=100, random_state=4)
model1.fit(X_train, y_train)
predictions1 = model1.predict(X_test)
mse1 = mean_squared_error(y_test, predictions1)
print("Mean Squared Error ", mse1)



region=[37, 60, 12, 35]  # the arabia region # [lon_min, lon_max, lat_min, lat_max]
latt=20   # set values
lonn=50
lwe1d = lwe.sel(lat=latt, lon=lonn, method='nearest')
# these are the values of nearest latitude and longitude
print(f"Nearest latitude: {lwe1d['lat'].values}")
print(f"Nearest longitude: {lwe1d['lon'].values}")

# Visualize the results
plt.plot(df.index[-len(y_test_):], y_test_, label='True Values')
plt.plot(df.index[-len(predictions_):], predictions_, label='Predictions')
plt.legend()
plt.show()


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error

# Assuming df is your DataFrame with time and lwet columns
df = pd.DataFrame(zip(lwe1d.time.values, lwe1d.values), columns=['time', 'lwet'])
df['time'] = pd.to_datetime(df['time'])

# Extract time series data
time_series = df.set_index('time')['lwet'].values

# Define a function to create time series sequences
def create_sequences(data, seq_length):
    sequences = []
    for i in range(len(data) - seq_length + 1):
        seq = data[i:i+seq_length]
        sequences.append(seq)
    return np.array(sequences)

# Set sequence length (you can adjust this based on your needs)
sequence_length = 10

# Create sequences for training
sequences = create_sequences(time_series, sequence_length)

# Split the sequences into input (X) and output (y)
X = sequences[:, :-1]  # All values except the last one in each sequence
y = sequences[:, -1]   # The last value in each sequence

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='RMSProp', loss='mean_squared_error')

# Define early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Reshape X_train and X_test to be 3D for LSTM input
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.1, callbacks=[early_stopping])

# Predict using the trained model
predictions = model.predict(X_test)

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, predictions)
print("Mean Squared Error: ", mse)
