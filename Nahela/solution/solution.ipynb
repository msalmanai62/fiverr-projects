{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data\n",
    "- #### features with discrete values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# NB_Classifier.py\n",
    "#\n",
    "# Implements the Naive Bayes classifier for simple probabilistic inference.\n",
    "# It assumes the existance of data in CSV format, where the first line contains\n",
    "# the names of random variables -- the last being the variable to predict.\n",
    "# This implementation aims to be agnostic of the data (no hardcoded vars/probs)\n",
    "#\n",
    "# Version: 1.0, Date: 03 October 2022\n",
    "# Version: 1.1, Date: 03 October 2023 more compatible with CPT_Generator\n",
    "# Version: 1.2, Date: 08 October 2023 more compatible with ModelEvaluator\n",
    "# Contact: hcuayahuitl@lincoln.ac.uk\n",
    "#############################################################################\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "class NB_Classifier:\n",
    "    rand_vars = []\n",
    "    rv_key_values = {}\n",
    "    rv_all_values = []\n",
    "    predictor_variable = None\n",
    "    num_data_instances = 0\n",
    "    default_missing_count = 0.000001\n",
    "    probabilities = {}\n",
    "    predictions = []\n",
    "    log_probabilities = False\n",
    "\n",
    "    def __init__(self, file_name, fitted_model=None):\n",
    "        if file_name is None:\n",
    "            return\n",
    "        else:\n",
    "            self.read_data(file_name)\n",
    "\n",
    "        if fitted_model is None:\n",
    "            self.training_time = time.time()\n",
    "            self.estimate_probabilities()\n",
    "            self.training_time = time.time() - self.training_time\n",
    "\n",
    "        else:\n",
    "            self.inference_time = time.time()\n",
    "            self.rv_key_values = fitted_model.rv_key_values\n",
    "            self.probabilities = fitted_model.probabilities\n",
    "            self.training_time = fitted_model.training_time\n",
    "            self.test_learnt_probabilities(file_name)\n",
    "            self.inference_time = time.time() - self.inference_time\n",
    "\n",
    "    def read_data(self, data_file):\n",
    "        print(\"\\nREADING data file %s...\" % (data_file))\n",
    "        print(\"---------------------------------------\")\n",
    "\n",
    "        self.rand_vars = []\n",
    "        self.rv_key_values = {}\n",
    "        self.rv_all_values = []\n",
    "\n",
    "        with open(data_file) as csv_file:\n",
    "            for line in csv_file:\n",
    "                line = line.strip()\n",
    "                if len(self.rand_vars) == 0:\n",
    "                    self.rand_vars = line.split(',')\n",
    "                    for variable in self.rand_vars:\n",
    "                        self.rv_key_values[variable] = []\n",
    "                else:\n",
    "                    values = line.split(',')\n",
    "                    self.rv_all_values.append(values)\n",
    "                    self.update_variable_key_values(values)\n",
    "                    self.num_data_instances += 1\n",
    "\n",
    "        self.predictor_variable = self.rand_vars[len(self.rand_vars)-1]\n",
    "\n",
    "        print(\"RANDOM VARIABLES=%s\" % (self.rand_vars))\n",
    "        print(\"VARIABLE KEY VALUES=%s\" % (self.rv_key_values))\n",
    "        print(\"VARIABLE VALUES (first 10)=%s\" % (self.rv_all_values[:10]))\n",
    "        print(\"PREDICTOR VARIABLE=%s\" % (self.predictor_variable))\n",
    "        print(\"|data instances|=%d\" % (self.num_data_instances))\n",
    "\n",
    "    def update_variable_key_values(self, values):\n",
    "        for i in range(0, len(self.rand_vars)):\n",
    "            variable = self.rand_vars[i]\n",
    "            key_values = self.rv_key_values[variable]\n",
    "            value_in_focus = values[i]\n",
    "            if value_in_focus not in key_values:\n",
    "                self.rv_key_values[variable].append(value_in_focus)\n",
    "\n",
    "    def estimate_probabilities(self):\n",
    "        countings = self.estimate_countings()\n",
    "        prior_counts = countings[self.predictor_variable]\n",
    "\n",
    "        print(\"\\nESTIMATING probabilities...\")\n",
    "        for variable, counts in countings.items():\n",
    "            prob_distribution = {}\n",
    "            for key, val in counts.items():\n",
    "                variables = key.split('|')\n",
    "\n",
    "                if len(variables) == 1:\n",
    "                    # prior probability\n",
    "                    probability = float(val/self.num_data_instances)\n",
    "                else:\n",
    "                    # conditional probability\n",
    "                    probability = float(val/prior_counts[variables[1]])\n",
    "\n",
    "                if self.log_probabilities is False:\n",
    "                    prob_distribution[key] = probability\n",
    "                else:\n",
    "                    # convert probability to log probability\n",
    "                    prob_distribution[key] = math.log(probability)\n",
    "\n",
    "            self.probabilities[variable] = prob_distribution\n",
    "\n",
    "        for variable, prob_dist in self.probabilities.items():\n",
    "            prob_mass = 0\n",
    "            for value, prob in prob_dist.items():\n",
    "                prob_mass += prob\n",
    "            print(\"P(%s)=>%s\\tSUM=%f\" % (variable, prob_dist, prob_mass))\n",
    "\n",
    "    def estimate_countings(self):\n",
    "        print(\"\\nESTIMATING countings...\")\n",
    "\n",
    "        countings = {}\n",
    "        for variable_index in range(0, len(self.rand_vars)):\n",
    "            variable = self.rand_vars[variable_index]\n",
    "\n",
    "            if variable_index == len(self.rand_vars)-1:\n",
    "                # prior counts\n",
    "                countings[variable] = self.get_counts(None)\n",
    "            else:\n",
    "                # conditional counts\n",
    "                countings[variable] = self.get_counts(variable_index)\n",
    "\n",
    "        print(\"countings=\"+str(countings))\n",
    "        return countings\n",
    "\n",
    "    def get_counts(self, variable_index):\n",
    "        counts = {}\n",
    "        predictor_index = len(self.rand_vars)-1\n",
    "\n",
    "        # accumulate countings\n",
    "        for values in self.rv_all_values:\n",
    "            if variable_index is None:\n",
    "                # case: prior probability\n",
    "                value = values[predictor_index]\n",
    "            else:\n",
    "                # case: conditional probability\n",
    "                value = values[variable_index]+\"|\"+values[predictor_index]\n",
    "\n",
    "            try:\n",
    "                counts[value] += 1\n",
    "            except Exception:\n",
    "                counts[value] = 1\n",
    "\n",
    "        # verify countings by checking missing prior/conditional counts\n",
    "        if variable_index is None:\n",
    "            counts = self.check_missing_prior_counts(counts)\n",
    "        else:\n",
    "            counts = self.check_missing_conditional_counts(counts, variable_index)\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def check_missing_prior_counts(self, counts):\n",
    "        for var_val in self.rv_key_values[self.predictor_variable]:\n",
    "            if var_val not in counts:\n",
    "                print(\"WARNING: missing count for variable=\" % (var_val))\n",
    "                counts[var_val] = self.default_missing_count\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def check_missing_conditional_counts(self, counts, variable_index):\n",
    "        variable = self.rand_vars[variable_index]\n",
    "        for var_val in self.rv_key_values[variable]:\n",
    "            for pred_val in self.rv_key_values[self.predictor_variable]:\n",
    "                pair = var_val+\"|\"+pred_val\n",
    "                if pair not in counts:\n",
    "                    print(\"WARNING: missing count for variables=%s\" % (pair))\n",
    "                    counts[pair] = self.default_missing_count\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def test_learnt_probabilities(self, file_name):\n",
    "        print(\"\\nEVALUATING on \"+str(file_name))\n",
    "\n",
    "        # iterate over all instances in the test data\n",
    "        for instance in self.rv_all_values:\n",
    "            distribution = {}\n",
    "            print(\"Input vector=%s\" % (instance))\n",
    "\n",
    "            # iterate over all values in the predictor variable\n",
    "            for predictor_value in self.rv_key_values[self.predictor_variable]:\n",
    "                prob_dist = self.probabilities[self.predictor_variable]\n",
    "                prob = prob_dist[predictor_value]\n",
    "\n",
    "                # iterate over all instance values except the predictor var.\n",
    "                for value_index in range(0, len(instance)-1):\n",
    "                    variable = self.rand_vars[value_index]\n",
    "                    value = instance[value_index]\n",
    "                    prob_dist = self.probabilities[variable]\n",
    "                    cond_prob = value+\"|\"+predictor_value\n",
    "\n",
    "                    if self.log_probabilities is False:\n",
    "                        prob *= prob_dist[cond_prob]\n",
    "                    else:\n",
    "                        prob += prob_dist[cond_prob]\n",
    "\n",
    "                distribution[predictor_value] = prob\n",
    "\n",
    "            normalised_dist = self.get_normalised_distribution(distribution)\n",
    "            self.predictions.append(normalised_dist)\n",
    "            print(\"UNNORMALISED DISTRIBUTION=%s\" % (distribution))\n",
    "            print(\"NORMALISED DISTRIBUTION=%s\" % (normalised_dist))\n",
    "            print(\"---\")\n",
    "\n",
    "    def get_normalised_distribution(self, distribution):\n",
    "        normalised_dist = {}\n",
    "        prob_mass = 0\n",
    "        for var_val, prob in distribution.items():\n",
    "            prob = math.exp(prob) if self.log_probabilities is True else prob\n",
    "            prob_mass += prob\n",
    "\n",
    "        for var_val, prob in distribution.items():\n",
    "            prob = math.exp(prob) if self.log_probabilities is True else prob\n",
    "            normalised_prob = prob/prob_mass\n",
    "            normalised_dist[var_val] = normalised_prob\n",
    "\n",
    "        return normalised_dist\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     if len(sys.argv) != 3:\n",
    "#         print(\"USAGE: NB_Classifier.py [train_file.csv] [test_file.csv]\")\n",
    "#         exit(0)\n",
    "#     else:\n",
    "#         file_name_train = sys.argv[1]\n",
    "#         file_name_test = sys.argv[2]\n",
    "#         nb_fitted = NB_Classifier(file_name_train)\n",
    "#         nb_tester = NB_Classifier(file_name_test, nb_fitted)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#    file_name_train = \"dataset/diabetes_data-discretized-train.csv\"\n",
    "#    file_name_test = \"dataset/diabetes_data-discretized-test.csv\"\n",
    "#    nb_fitted = NB_Classifier(file_name_train)\n",
    "#    nb_tester = NB_Classifier(file_name_test, nb_fitted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "READING data file diabetes-config.txt...\n",
      "RAW key-values={'name': ' Diabetes_BayesianNetwork', 'random_variables': ' Pregnancies;Glucose;BloodPressure;SkinThickness;Insulin;BMI;DiabetesPedigreeFunction;Age;Outcome', 'structure': ' P(Outcome); P(Glucose|Outcome);P(BMI|Outcome);P(Age|Outcome)', 'random_variables_raw': ' Pregnancies;Glucose;BloodPressure;SkinThickness;Insulin;BMI;DiabetesPedigreeFunction;Age;Outcome'}\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# BayesNetReader.py\n",
    "#\n",
    "# Reads a configuration file containing the specification of a Bayes net.\n",
    "# It generates a dictionary of key-value pairs containing information\n",
    "# describing the random variables, structure, and conditional probabilities.\n",
    "# This implementation aims to be agnostic of the data (no hardcoded vars/probs)\n",
    "#\n",
    "# Keys expected: name, random_variables, structure, and CPTs.\n",
    "# Separators: COLON(:) for key-values, EQUALS(=) for table_entry-probabilities\n",
    "# Example configuration file: see config_alarm.txt (from workshop of week 3)\n",
    "#\n",
    "# Version: 1.0\n",
    "# Date: 06 October 2022\n",
    "# Contact: hcuayahuitl@lincoln.ac.uk\n",
    "#############################################################################\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "class BayesNetReader:\n",
    "    bn = {}\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        self.read_data(file_name)\n",
    "        # self.tokenise_data()\n",
    "\n",
    "    def read_data(self, data_file):\n",
    "        print(\"\\nREADING data file %s...\" % (data_file))\n",
    "\n",
    "        with open(data_file) as cfg_file:\n",
    "            key = None\n",
    "            value = None\n",
    "            for line in cfg_file:\n",
    "                line = line.strip()\n",
    "                if len(line) == 0:\n",
    "                    continue\n",
    "\n",
    "                tokens = line.split(\":\")\n",
    "                if len(tokens) == 2:\n",
    "                    if value is not None:\n",
    "                        self.bn[key] = value\n",
    "                        value = None\n",
    "\n",
    "                    key = tokens[0]\n",
    "                    value = tokens[1]\n",
    "                else:\n",
    "                    value += tokens[0]\n",
    "\n",
    "        self.bn[key] = value\n",
    "        self.bn[\"random_variables_raw\"] = self.bn[\"random_variables\"]\n",
    "        print(\"RAW key-values=\"+str(self.bn))\n",
    "\n",
    "    # def tokenise_data(self):\n",
    "    #     print(\"TOKENISING data...\")\n",
    "    #     rv_key_values = {}\n",
    "\n",
    "    #     for key, values in self.bn.items():\n",
    "\n",
    "    #         if key == \"random_variables\":\n",
    "    #             var_set = []\n",
    "    #             for value in values.split(\";\"):\n",
    "    #                 if value.find(\"(\") and value.find(\")\"):\n",
    "    #                     value = value.replace('(', ' ')\n",
    "    #                     value = value.replace(')', ' ')\n",
    "    #                     parts = value.split(' ')\n",
    "    #                     var_set.append(parts[1].strip())\n",
    "    #                 else:\n",
    "    #                     var_set.append(value)\n",
    "    #             self.bn[key] = var_set\n",
    "\n",
    "    #         elif key.startswith(\"CPT\"):\n",
    "    #             # store Conditional Probability Tables (CPTs) as dictionaries\n",
    "    #             cpt = {}\n",
    "    #             sum = 0\n",
    "    #             for value in values.split(\";\"):\n",
    "    #                 pair = value.split(\"=\")\n",
    "    #                 cpt[pair[0]] = float(pair[1])\n",
    "    #                 sum += float(pair[1])\n",
    "    #             print(\"key=%s cpt=%s sum=%s\" % (key, cpt, sum))\n",
    "    #             self.bn[key] = cpt\n",
    "\n",
    "    #             # store unique values for each random variable\n",
    "    #             if key.find(\"|\") > 0:\n",
    "    #                 rand_var = key[4:].split(\"|\")[0]\n",
    "    #             else:\n",
    "    #                 rand_var = key[4:].split(\")\")[0]\n",
    "    #             unique_values = list(cpt.keys())\n",
    "    #             rv_key_values[rand_var] = unique_values\n",
    "\n",
    "    #         else:\n",
    "    #             values = values.split(\";\")\n",
    "    #             if len(values) > 1:\n",
    "    #                 self.bn[key] = values\n",
    "\n",
    "    #     self.bn['rv_key_values'] = rv_key_values\n",
    "    #     print(\"TOKENISED key-values=\"+str(self.bn))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # if len(sys.argv) != 2:\n",
    "    #     print(\"USAGE: BayesNetReader.py [your_config_file.txt]\")\n",
    "    # else:\n",
    "    #     # file_name = sys.argv[1]\n",
    "        file_name = \"diabetes-config.txt\"\n",
    "        BayesNetReader(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPT Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdp_Outcome\n",
      " +------------+----------+\n",
      "| Outcome(0) | 0.646766 |\n",
      "+------------+----------+\n",
      "| Outcome(1) | 0.353234 |\n",
      "+------------+----------+\n",
      "cdp_Glucose\n",
      " +------------+-----------+\n",
      "| Glucose(0) | 0.0066335 |\n",
      "+------------+-----------+\n",
      "| Glucose(1) | 0.116086  |\n",
      "+------------+-----------+\n",
      "| Glucose(2) | 0.416252  |\n",
      "+------------+-----------+\n",
      "| Glucose(3) | 0.296849  |\n",
      "+------------+-----------+\n",
      "| Glucose(4) | 0.131012  |\n",
      "+------------+-----------+\n",
      "| Glucose(5) | 0.0331675 |\n",
      "+------------+-----------+\n",
      "\n",
      "cdp_Age\n",
      " +--------+-----------+\n",
      "| Age(1) | 0.0829187 |\n",
      "+--------+-----------+\n",
      "| Age(2) | 0.538972  |\n",
      "+--------+-----------+\n",
      "| Age(3) | 0.205638  |\n",
      "+--------+-----------+\n",
      "| Age(4) | 0.107794  |\n",
      "+--------+-----------+\n",
      "| Age(5) | 0.0646766 |\n",
      "+--------+-----------+\n",
      "\n",
      "cdp_BMI\n",
      " +--------+------------+\n",
      "| BMI(0) | 0.00995025 |\n",
      "+--------+------------+\n",
      "| BMI(1) | 0.111111   |\n",
      "+--------+------------+\n",
      "| BMI(2) | 0.359867   |\n",
      "+--------+------------+\n",
      "| BMI(3) | 0.391376   |\n",
      "+--------+------------+\n",
      "| BMI(4) | 0.101161   |\n",
      "+--------+------------+\n",
      "| BMI(5) | 0.026534   |\n",
      "+--------+------------+\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NaiveBayes.active_trail_nodes() got an unexpected keyword argument 'variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m evidence \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Perform inference on the 'Outcome' variable given the evidence\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mve\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutcome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\PMYLS\\envs\\ai\\Lib\\site-packages\\pgmpy\\inference\\ExactInference.py:317\u001b[0m, in \u001b[0;36mVariableElimination.query\u001b[1;34m(self, variables, evidence, virtual_evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Step 3: Prune the network based on variables and evidence.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, BayesianNetwork):\n\u001b[1;32m--> 317\u001b[0m     model_reduced, evidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prune_bayesian_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     factors \u001b[38;5;241m=\u001b[39m model_reduced\u001b[38;5;241m.\u001b[39mcpds\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PMYLS\\envs\\ai\\Lib\\site-packages\\pgmpy\\inference\\base.py:153\u001b[0m, in \u001b[0;36mInference._prune_bayesian_model\u001b[1;34m(self, variables, evidence)\u001b[0m\n\u001b[0;32m    149\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnodes()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(variables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(variables)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Step 1: Remove all the variables that are d-separated from `variables` when conditioned\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m#         on `evidence`\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_trail_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39md_connected\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39munion(evidence\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    157\u001b[0m bn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msubgraph(d_connected)\n",
      "\u001b[1;31mTypeError\u001b[0m: NaiveBayes.active_trail_nodes() got an unexpected keyword argument 'variables'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pgmpy.models import NaiveBayes\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('dataset/diabetes_data-discretized-train.csv')\n",
    "test_data = pd.read_csv('dataset/diabetes_data-discretized-test.csv', usecols=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'])\n",
    "\n",
    "\n",
    "# Define the model structure (Naive Bayes)\n",
    "model = NaiveBayes()\n",
    "model.add_node('Outcome')  # Target variable\n",
    "model.add_nodes_from(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "                      'DiabetesPedigreeFunction', 'Age'])  # Other variables\n",
    "\n",
    "# Fit the model using Maximum Likelihood Estimation\n",
    "estimator = MaximumLikelihoodEstimator(model, train_data)\n",
    "cdp_Outcome = estimator.estimate_cpd('Outcome')  # Estimate Conditional Probability Distribution\n",
    "cdp_Glucose = estimator.estimate_cpd('Glucose')\n",
    "cdp_Pregnancies = estimator.estimate_cpd('Pregnancies')\n",
    "cdp_BloodPressure = estimator.estimate_cpd('BloodPressure')\n",
    "cdp_SkinThickness = estimator.estimate_cpd('SkinThickness')\n",
    "cdp_Insulin = estimator.estimate_cpd('Insulin')\n",
    "cdp_Age = estimator.estimate_cpd('Age') \n",
    "cdp_BMI = estimator.estimate_cpd('BMI') \n",
    "cdp_DiabetesPedigreeFunction = estimator.estimate_cpd('DiabetesPedigreeFunction') \n",
    "\n",
    "\n",
    "print('cdp_Outcome\\n',cdp_Outcome)\n",
    "print('cdp_Glucose\\n',cdp_Glucose)\n",
    "print('\\ncdp_Age\\n',cdp_Age)\n",
    "print('\\ncdp_BMI\\n',cdp_BMI)\n",
    "\n",
    "model.add_cpds(cdp_Glucose, cdp_Age, cdp_BMI, cdp_Outcome, cdp_Pregnancies, cdp_BloodPressure, cdp_SkinThickness, cdp_Insulin, cdp_DiabetesPedigreeFunction)\n",
    "\n",
    "# Create an instance of the VariableElimination class\n",
    "ve = VariableElimination(model)\n",
    "\n",
    "# Perform inference on the test set\n",
    "# Example evidence (replace 'value' with actual values from your test dataset)\n",
    "# evidence = {'Pregnancies': 'value', 'Glucose': 'value', 'BloodPressure': 'value',\n",
    "#             'SkinThickness': 'value', 'Insulin': 'value', 'BMI': 'value',\n",
    "#             'DiabetesPedigreeFunction': 'value', 'Age': 'value'}\n",
    "evidence = test_data.to_dict(orient='records')[10]\n",
    "\n",
    "\n",
    "# Perform inference on the 'Outcome' variable given the evidence\n",
    "result = ve.query(variables=['Outcome'], evidence=evidence, joint=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MaximumLikelihoodEstimator.estimate_cpd() got an unexpected keyword argument 'prior_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m estimator \u001b[38;5;241m=\u001b[39m MaximumLikelihoodEstimator(model, train_data)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPregnancies\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlucose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBloodPressure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkinThickness\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsulin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBMI\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetesPedigreeFunction\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 19\u001b[0m     cpd \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_cpd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdirichlet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpseudo_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39madd_cpds(cpd)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Estimate CPD for the target variable 'Outcome'\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: MaximumLikelihoodEstimator.estimate_cpd() got an unexpected keyword argument 'prior_type'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pgmpy.models import NaiveBayes\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('dataset/diabetes_data-discretized-train.csv')\n",
    "test_data = pd.read_csv('dataset/diabetes_data-discretized-test.csv', usecols=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'])\n",
    "\n",
    "# Define the model structure (Naive Bayes)\n",
    "model = NaiveBayes()\n",
    "model.add_node('Outcome')  # Target variable\n",
    "model.add_nodes_from(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "                      'DiabetesPedigreeFunction', 'Age'])  # Other variables\n",
    "\n",
    "# Fit the model using Maximum Likelihood Estimation for each feature variable\n",
    "estimator = MaximumLikelihoodEstimator(model, train_data)\n",
    "for feature in ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "                'DiabetesPedigreeFunction', 'Age']:\n",
    "    cpd = estimator.estimate_cpd(feature, prior_type=\"dirichlet\", pseudo_counts=0.5)\n",
    "    model.add_cpds(cpd)\n",
    "\n",
    "# Estimate CPD for the target variable 'Outcome'\n",
    "cpd_Outcome = estimator.estimate_cpd('Outcome', prior_type=\"dirichlet\", pseudo_counts=0.5)\n",
    "model.add_cpds(cpd_Outcome)\n",
    "\n",
    "# Create an instance of the VariableElimination class\n",
    "ve = VariableElimination(model)\n",
    "\n",
    "# Perform inference on the test set\n",
    "evidence = test_data.to_dict(orient='records')[10]\n",
    "\n",
    "# Perform inference on the 'Outcome' variable given the evidence\n",
    "result = ve.query(variables=['Outcome'], evidence=evidence, joint=False)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "# Load your data (make sure your data is loaded as a pandas DataFrame)\n",
    "data = pd.read_csv('dataset/diabetes_data-discretized-train.csv')\n",
    "data_test = pd.read_csv('dataset/diabetes_data-discretized-test.csv', usecols=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'])\n",
    "\n",
    "# Define the structure of your Bayesian Network\n",
    "model = BayesianNetwork([('Pregnancies', 'Outcome'), ('Glucose', 'Outcome'), ('BloodPressure', 'Outcome'),\n",
    "                         ('SkinThickness', 'Outcome'), ('Insulin', 'Outcome'), ('BMI', 'Outcome'),\n",
    "                         ('DiabetesPedigreeFunction', 'Outcome'), ('Age', 'Outcome')])\n",
    "\n",
    "# Estimate the CPDs using Maximum Likelihood Estimation\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Create an instance of the VariableElimination class\n",
    "ve = VariableElimination(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "| Outcome    |   phi(Outcome) |\n",
      "+============+================+\n",
      "| Outcome(0) |         0.5000 |\n",
      "+------------+----------------+\n",
      "| Outcome(1) |         0.5000 |\n",
      "+------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "# Convert test data to a dictionary to use as evidence\n",
    "evidence = data_test.to_dict(orient='records')[10]\n",
    "\n",
    "# Perform inference on the 'Outcome' variable given the evidence\n",
    "result = ve.query(variables=['Outcome'], evidence=evidence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
